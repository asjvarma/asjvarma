{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaiEkGLXiTRsh+Mhs+lQsV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asjvarma/asjvarma/blob/main/11590786_Jayanth_Varma_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f7lz_aR12Qx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"twitter_sentiment_pytorch\n",
        "\n",
        "#importing modules/packages\n",
        "import os\n",
        "import gensim\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch \n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import tqdm\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import random_split, SubsetRandomSampler, ConcatDataset\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "from string import punctuation\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "punctuation = list(punctuation)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore')\n",
        "\n",
        "#reading data files\n",
        "train_text = pd.read_csv(\"/content/sample_data/dataset/train_text.txt\", sep=\"\\r\\n\", names=[\"tweets\"])\n",
        "train_labels = pd.read_csv(\"/content/sample_data/dataset/train_labels.txt\", sep=\"\\r\\n\", names=[\"labels\"])\n",
        "\n",
        "val_text = pd.read_csv(\"/content/sample_data/dataset/val_text.txt\", sep=\"\\r\\n\", names=[\"tweets\"])\n",
        "val_labels = pd.read_csv(\"/content/sample_data/dataset/val_labels.txt\", sep=\"\\r\\n\", names=[\"labels\"])\n",
        "\n",
        "test_text = pd.read_csv(\"/content/sample_data/dataset/test_text.txt\", sep=\"\\r\\n\", names=[\"tweets\"])\n",
        "test_labels = pd.read_csv(\"/content/sample_data/dataset/test_labels.txt\", sep=\"\\r\\n\", names=[\"labels\"])\n",
        "\n",
        "# define function to clean tweets\n",
        "def clean_tweets(tweet):\n",
        "    # tweet to lowercase\n",
        "    tweet = tweet.lower()\n",
        "    # instantiate tokenizer class\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    #tweet tokenize\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    clean_tweet = [token for token in tokens if token not in punctuation]\n",
        "\n",
        "    return clean_tweet\n",
        "\n",
        "#clean tweets texts\n",
        "train_text['clean_tweets'] = train_text['tweets'].apply(lambda x: (clean_tweets(x)))\n",
        "test_text['clean_tweets'] = test_text['tweets'].apply(lambda x: (clean_tweets(x)))\n",
        "val_text['clean_tweets'] = val_text['tweets'].apply(lambda x: (clean_tweets(x)))\n",
        "\n",
        "#creating Word2Vec model\n",
        "X = train_text['clean_tweets']\n",
        "w2v_model = Word2Vec(X, size=50, window=5, min_count=1)\n",
        "\n",
        "vocabs = {}\n",
        "for id, vocab in enumerate(w2v_model.wv.vocab):\n",
        "    vocabs[vocab] = id + 2\n",
        "\n",
        "#longest sentence length\n",
        "length = train_text['clean_tweets'].apply(lambda x: ([len(x)])).max()[0]\n",
        "\n",
        "#replacing tweet words with their respective ids from vocabs list\n",
        "def check_word_fill(words):\n",
        "    ids = []\n",
        "    for word in words:\n",
        "        if word in vocabs:\n",
        "            ids.append(vocabs[word])\n",
        "        else:\n",
        "            ids.append(1)\n",
        "    if len(ids) < length:\n",
        "      for j in range(length-len(ids)):\n",
        "        ids.append(0)\n",
        "    \n",
        "    return ids\n",
        "\n",
        "#train\n",
        "train_text['words_ids'] = train_text['clean_tweets'].apply(lambda x:(check_word_fill(x)))\n",
        "train_text['to_tensors'] = train_text['words_ids'].apply(lambda x:torch.LongTensor(x))\n",
        "train_text_stack = torch.stack(list(train_text['to_tensors'].values))\n",
        "\n",
        "#test\n",
        "test_text['words_ids'] = test_text['clean_tweets'].apply(lambda x:(check_word_fill(x)))\n",
        "test_text['to_tensors'] = test_text['words_ids'].apply(lambda x:torch.LongTensor(x))\n",
        "test_text_stack = torch.stack(list(test_text['to_tensors'].values))\n",
        "\n",
        "#val\n",
        "val_text['words_ids'] = val_text['clean_tweets'].apply(lambda x:(check_word_fill(x)))\n",
        "val_text['to_tensors'] = val_text['words_ids'].apply(lambda x:torch.LongTensor(x))\n",
        "val_text_stack = torch.stack(list(val_text['to_tensors'].values))\n",
        "\n",
        "#get vocabulary vectors\n",
        "vec = w2v_model.wv.vectors\n",
        "min_vec = w2v_model.wv.vectors.min()\n",
        "max_vec = w2v_model.wv.vectors.max()\n",
        "vec_len = 50\n",
        "\n",
        "pre_trained_emb = pd.np.insert(vec, 0, pd.np.random.uniform(min_vec, max_vec, vec_len), axis=0)  \n",
        "pre_trained_emb = torch.FloatTensor(pd.np.insert(pre_trained_emb, 0, pd.np.zeros(vec_len),axis=0))\n",
        "\n",
        "# Model\n",
        "class NetworkModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_size):\n",
        "        super().__init__()\n",
        "        # self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding = nn.EmbeddingBag.from_pretrained(pre_trained_emb)\n",
        "        self.linear1 = nn.Linear(embedding_dim, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "    \n",
        "    def forward(self, seq):\n",
        "        input = self.embedding(seq)\n",
        "        pred1 = self.linear1(input)\n",
        "        pred1 = self.relu(pred1)\n",
        "        pred2 = self.linear2(pred1).squeeze()\n",
        "        \n",
        "        return pred2\n",
        "\n",
        "#model instantiation\n",
        "model = NetworkModel(embedding_dim = 50, hidden_size = 25)\n",
        "\n",
        "#loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-3)\n",
        "# model\n",
        "\n",
        "#datasets \n",
        "training_dataset = data.TensorDataset(train_text_stack, torch.FloatTensor(train_labels['labels'].values))\n",
        "valid_dataset = data.TensorDataset(val_text_stack, torch.FloatTensor(val_labels['labels'].values))\n",
        "testing_dataset = data.TensorDataset(test_text_stack, torch.FloatTensor(test_labels['labels'].values))\n",
        "\n",
        "#concat training, testing & valid\n",
        "dataset = ConcatDataset([training_dataset, valid_dataset])\n",
        "\n",
        "test_dataloader = data.DataLoader(testing_dataset, batch_size=4)\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "epochs = 50\n",
        "def train_val_test(epochs, model, optimizer, criterion, train_dataloader, valid_dataloader, test_dataloader):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        #set loss to zero\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        test_loss = 0.0\n",
        "\n",
        "        # set acc to zero\n",
        "        trainrunning_corrects = 0\n",
        "        train_corrects = 0\n",
        "        vrunning_corrects = 0\n",
        "        val_corrects = 0\n",
        "        testrunning_corrects = 0\n",
        "        test_corrects = 0\n",
        "        \n",
        "        #set model for train\n",
        "        model.train()\n",
        "        \n",
        "        for id, batch in enumerate(train_dataloader):\n",
        "            # [tweets, label]\n",
        "            target, labels = batch\n",
        "            \n",
        "            #optimizer, clear the gradients  \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #Forward Pass\n",
        "            predict = model(target)\n",
        "            _, pred = torch.max(predict, 0)\n",
        "            \n",
        "            # Find the Loss\n",
        "            loss = criterion(predict, labels)\n",
        "            \n",
        "            # Calculate gradients \n",
        "            loss.backward()\n",
        "            \n",
        "            # Update Weights\n",
        "            optimizer.step()\n",
        "\n",
        "            #accuracy\n",
        "            trainrunning_corrects += (pred == labels).sum()\n",
        "            train_corrects += pred\n",
        "            \n",
        "            # Calculate Loss\n",
        "            train_loss = loss.item() * target.size(0)\n",
        "            \n",
        "        training_loss = train_loss/len(train_dataloader)\n",
        "        training_acc = (trainrunning_corrects.double()*100) / train_corrects\n",
        "        \n",
        "        #set model for evalution\n",
        "        model.eval()\n",
        "        for id, batch in enumerate(valid_dataloader):\n",
        "            # [tweets, labels]\n",
        "            target, labels = batch\n",
        "            \n",
        "            predict = model(target)\n",
        "            _, pred = torch.max(predict, 0)\n",
        "\n",
        "            loss = criterion(predict, labels)\n",
        "\n",
        "            valid_loss = loss.item() * target.size(0)\n",
        "\n",
        "            #accuracy\n",
        "            vrunning_corrects += (pred == labels).sum()\n",
        "            val_corrects += pred\n",
        "            \n",
        "\n",
        "        val_loss = valid_loss/len(valid_dataloader)\n",
        "        val_acc = (vrunning_corrects.double()*100) / val_corrects\n",
        "\n",
        "        # testing model\n",
        "        for id, batch in enumerate(test_dataloader):\n",
        "            # [tweets, labels]\n",
        "            target, labels = batch\n",
        "            \n",
        "            predict = model(target)\n",
        "            _, pred = torch.max(predict, 0)\n",
        "            y_pred.extend(predict)\n",
        "\n",
        "            loss = criterion(predict, labels)\n",
        "            y_true.extend(labels)\n",
        "\n",
        "            test_loss = loss.item() * target.size(0)\n",
        "\n",
        "            #accuracy\n",
        "            testrunning_corrects += (pred == labels).sum()\n",
        "            test_corrects += pred\n",
        "        \n",
        "        testing_loss = test_loss/len(test_dataloader)\n",
        "        testing_acc = (testrunning_corrects.double()*100) / test_corrects\n",
        "\n",
        "        print('Epoch: {}, Training Loss: {:.4f}, Acc {:.4f}, Validation Loss: {:.4f}, Acc {:.4f}, Testing Loss: {:.4f}, Acc {:.4f},'.\\\n",
        "              format(epoch+1, training_loss, training_acc, val_loss, val_acc, testing_loss, testing_acc))\n",
        "\n",
        "k = 3\n",
        "splits = KFold(n_splits = k, shuffle=True, random_state=42)\n",
        "fold_performance = {}\n",
        "\n",
        "for fold, (train, val) in enumerate(splits.split(np.arange(len(dataset)))):\n",
        "\n",
        "    print(f'\\n************* Fold : { fold + 1 } **************')\n",
        "\n",
        "    train_sample = SubsetRandomSampler(train)\n",
        "    val_sample = SubsetRandomSampler(val)\n",
        "    \n",
        "    train_dataloader = data.DataLoader(dataset, batch_size=4, sampler=train_sample)\n",
        "    val_dataloader = data.DataLoader(dataset, batch_size=4, sampler=val_sample)\n",
        "\n",
        "    train_val_test(epochs, model, optimizer, criterion, train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "confusion_matrix = torch.zeros(9, 9)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_dataloader):\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 0)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(confusion_matrix, annot = True, fmt = '0.3f', linewidth=0.5, square = True, cbar = False)\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.xlabel(\"y_pred\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3295
        },
        "id": "zLCS2ybV2cHA",
        "outputId": "0df54567-e0f8-4814-a413-70190b982b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "************* Fold : 1 **************\n",
            "Epoch: 1, Training Loss: 0.0012, Acc 65.4922, Validation Loss: 0.0098, Acc 67.4203, Testing Loss: 0.0069, Acc 67.6659,\n",
            "Epoch: 2, Training Loss: 0.0020, Acc 65.5759, Validation Loss: 0.0072, Acc 65.1951, Testing Loss: 0.0072, Acc 68.9023,\n",
            "Epoch: 3, Training Loss: 0.0017, Acc 67.0802, Validation Loss: 0.0054, Acc 67.4280, Testing Loss: 0.0072, Acc 67.7922,\n",
            "Epoch: 4, Training Loss: 0.0021, Acc 68.3731, Validation Loss: 0.0069, Acc 67.4825, Testing Loss: 0.0071, Acc 66.0418,\n",
            "Epoch: 5, Training Loss: 0.0013, Acc 65.8988, Validation Loss: 0.0068, Acc 66.4495, Testing Loss: 0.0072, Acc 68.6005,\n",
            "Epoch: 6, Training Loss: 0.0017, Acc 68.5275, Validation Loss: 0.0069, Acc 64.5865, Testing Loss: 0.0070, Acc 68.2975,\n",
            "Epoch: 7, Training Loss: 0.0012, Acc 63.9200, Validation Loss: 0.0082, Acc 69.2294, Testing Loss: 0.0072, Acc 69.2342,\n",
            "Epoch: 8, Training Loss: 0.0017, Acc 67.3404, Validation Loss: 0.0083, Acc 65.3316, Testing Loss: 0.0069, Acc 67.9059,\n",
            "Epoch: 9, Training Loss: 0.0012, Acc 69.9519, Validation Loss: 0.0056, Acc 66.2843, Testing Loss: 0.0070, Acc 66.8426,\n",
            "Epoch: 10, Training Loss: 0.0017, Acc 66.2173, Validation Loss: 0.0057, Acc 65.5352, Testing Loss: 0.0070, Acc 69.5342,\n",
            "Epoch: 11, Training Loss: 0.0013, Acc 67.4951, Validation Loss: 0.0097, Acc 65.8553, Testing Loss: 0.0070, Acc 65.7186,\n",
            "Epoch: 12, Training Loss: 0.0016, Acc 67.8248, Validation Loss: -0.0000, Acc 67.5557, Testing Loss: 0.0071, Acc 66.1816,\n",
            "Epoch: 13, Training Loss: 0.0013, Acc 66.2866, Validation Loss: 0.0083, Acc 63.4066, Testing Loss: 0.0073, Acc 66.3983,\n",
            "Epoch: 14, Training Loss: 0.0017, Acc 65.8363, Validation Loss: 0.0098, Acc 66.2069, Testing Loss: 0.0071, Acc 66.9508,\n",
            "Epoch: 15, Training Loss: 0.0012, Acc 67.6997, Validation Loss: 0.0101, Acc 68.2123, Testing Loss: 0.0072, Acc 69.5729,\n",
            "Epoch: 16, Training Loss: 0.0021, Acc 67.0576, Validation Loss: 0.0083, Acc 67.9360, Testing Loss: 0.0071, Acc 68.9670,\n",
            "Epoch: 17, Training Loss: 0.0017, Acc 66.4025, Validation Loss: 0.0098, Acc 67.3272, Testing Loss: 0.0072, Acc 69.3774,\n",
            "Epoch: 18, Training Loss: 0.0021, Acc 66.5461, Validation Loss: 0.0071, Acc 67.6353, Testing Loss: 0.0070, Acc 69.8381,\n",
            "Epoch: 19, Training Loss: 0.0012, Acc 66.3639, Validation Loss: 0.0039, Acc 65.0442, Testing Loss: 0.0070, Acc 68.1858,\n",
            "Epoch: 20, Training Loss: 0.0017, Acc 65.0636, Validation Loss: 0.0056, Acc 64.8352, Testing Loss: 0.0069, Acc 66.7106,\n",
            "Epoch: 21, Training Loss: 0.0021, Acc 65.9820, Validation Loss: 0.0086, Acc 66.5878, Testing Loss: 0.0070, Acc 67.0337,\n",
            "Epoch: 22, Training Loss: 0.0012, Acc 67.7583, Validation Loss: 0.0069, Acc 65.1035, Testing Loss: 0.0069, Acc 65.8377,\n",
            "Epoch: 23, Training Loss: 0.0016, Acc 66.8186, Validation Loss: 0.0082, Acc 68.3910, Testing Loss: 0.0073, Acc 65.9765,\n",
            "Epoch: 24, Training Loss: 0.0012, Acc 67.6581, Validation Loss: 0.0069, Acc 67.7343, Testing Loss: 0.0071, Acc 68.6080,\n",
            "Epoch: 25, Training Loss: 0.0012, Acc 67.9225, Validation Loss: 0.0015, Acc 67.2011, Testing Loss: 0.0072, Acc 69.1300,\n",
            "Epoch: 26, Training Loss: 0.0016, Acc 66.8710, Validation Loss: 0.0070, Acc 67.7080, Testing Loss: 0.0072, Acc 68.2038,\n",
            "Epoch: 27, Training Loss: 0.0025, Acc 67.0969, Validation Loss: 0.0070, Acc 64.2762, Testing Loss: 0.0070, Acc 67.5473,\n",
            "Epoch: 28, Training Loss: 0.0016, Acc 65.4630, Validation Loss: 0.0097, Acc 65.5627, Testing Loss: 0.0072, Acc 67.0462,\n",
            "Epoch: 29, Training Loss: 0.0013, Acc 67.4092, Validation Loss: 0.0070, Acc 66.3096, Testing Loss: 0.0071, Acc 68.1086,\n",
            "Epoch: 30, Training Loss: 0.0021, Acc 67.0243, Validation Loss: 0.0084, Acc 66.4305, Testing Loss: 0.0070, Acc 69.3945,\n",
            "Epoch: 31, Training Loss: 0.0008, Acc 65.9338, Validation Loss: 0.0027, Acc 69.3172, Testing Loss: 0.0071, Acc 69.2768,\n",
            "Epoch: 32, Training Loss: 0.0008, Acc 66.2495, Validation Loss: 0.0083, Acc 64.6261, Testing Loss: 0.0071, Acc 67.1603,\n",
            "Epoch: 33, Training Loss: 0.0021, Acc 65.4867, Validation Loss: 0.0098, Acc 64.5766, Testing Loss: 0.0073, Acc 69.4395,\n",
            "Epoch: 34, Training Loss: 0.0013, Acc 66.0618, Validation Loss: 0.0026, Acc 66.8551, Testing Loss: 0.0071, Acc 67.1926,\n",
            "Epoch: 35, Training Loss: 0.0021, Acc 68.2133, Validation Loss: 0.0084, Acc 64.6562, Testing Loss: 0.0070, Acc 67.3951,\n",
            "Epoch: 36, Training Loss: 0.0012, Acc 68.7705, Validation Loss: 0.0083, Acc 67.6999, Testing Loss: 0.0073, Acc 68.3429,\n",
            "Epoch: 37, Training Loss: 0.0008, Acc 66.9214, Validation Loss: 0.0097, Acc 66.4497, Testing Loss: 0.0071, Acc 68.9305,\n",
            "Epoch: 38, Training Loss: 0.0012, Acc 66.2959, Validation Loss: 0.0099, Acc 67.9736, Testing Loss: 0.0072, Acc 67.0855,\n",
            "Epoch: 39, Training Loss: 0.0016, Acc 66.4312, Validation Loss: 0.0067, Acc 68.4032, Testing Loss: 0.0071, Acc 65.6636,\n",
            "Epoch: 40, Training Loss: 0.0013, Acc 64.4846, Validation Loss: 0.0056, Acc 63.3542, Testing Loss: 0.0072, Acc 66.1132,\n",
            "Epoch: 41, Training Loss: 0.0021, Acc 66.6471, Validation Loss: 0.0100, Acc 66.7891, Testing Loss: 0.0071, Acc 66.7832,\n",
            "Epoch: 42, Training Loss: 0.0022, Acc 67.4145, Validation Loss: 0.0097, Acc 66.7569, Testing Loss: 0.0070, Acc 67.4923,\n",
            "Epoch: 43, Training Loss: 0.0021, Acc 66.5215, Validation Loss: 0.0098, Acc 65.9417, Testing Loss: 0.0071, Acc 66.6081,\n",
            "Epoch: 44, Training Loss: 0.0025, Acc 67.8541, Validation Loss: 0.0068, Acc 65.6387, Testing Loss: 0.0072, Acc 69.0788,\n",
            "Epoch: 45, Training Loss: 0.0013, Acc 66.2851, Validation Loss: 0.0097, Acc 66.4086, Testing Loss: 0.0071, Acc 68.2911,\n",
            "Epoch: 46, Training Loss: 0.0021, Acc 65.9695, Validation Loss: 0.0085, Acc 65.7276, Testing Loss: 0.0070, Acc 67.6529,\n",
            "Epoch: 47, Training Loss: 0.0004, Acc 66.6445, Validation Loss: 0.0084, Acc 68.1826, Testing Loss: 0.0070, Acc 66.6159,\n",
            "Epoch: 48, Training Loss: 0.0021, Acc 66.6834, Validation Loss: 0.0040, Acc 67.7138, Testing Loss: 0.0072, Acc 66.6014,\n",
            "Epoch: 49, Training Loss: 0.0008, Acc 66.8176, Validation Loss: 0.0071, Acc 70.3317, Testing Loss: 0.0070, Acc 69.1300,\n",
            "Epoch: 50, Training Loss: 0.0015, Acc 67.2106, Validation Loss: 0.0057, Acc 65.5270, Testing Loss: 0.0071, Acc 68.5107,\n",
            "\n",
            "************* Fold : 2 **************\n",
            "Epoch: 1, Training Loss: 0.0017, Acc 65.3133, Validation Loss: 0.0082, Acc 65.3378, Testing Loss: 0.0072, Acc 68.0753,\n",
            "Epoch: 2, Training Loss: 0.0016, Acc 68.2590, Validation Loss: 0.0084, Acc 68.3333, Testing Loss: 0.0072, Acc 67.9763,\n",
            "Epoch: 3, Training Loss: 0.0021, Acc 65.7189, Validation Loss: 0.0071, Acc 68.6753, Testing Loss: 0.0072, Acc 67.2846,\n",
            "Epoch: 4, Training Loss: 0.0017, Acc 66.5917, Validation Loss: 0.0070, Acc 67.0126, Testing Loss: 0.0071, Acc 69.2428,\n",
            "Epoch: 5, Training Loss: 0.0017, Acc 66.5768, Validation Loss: 0.0084, Acc 65.8650, Testing Loss: 0.0070, Acc 68.2772,\n",
            "Epoch: 6, Training Loss: 0.0021, Acc 64.3886, Validation Loss: 0.0097, Acc 67.7169, Testing Loss: 0.0071, Acc 67.8719,\n",
            "Epoch: 7, Training Loss: 0.0013, Acc 65.9864, Validation Loss: 0.0070, Acc 66.1562, Testing Loss: 0.0072, Acc 67.8469,\n",
            "Epoch: 8, Training Loss: 0.0017, Acc 66.4208, Validation Loss: 0.0071, Acc 66.1757, Testing Loss: 0.0073, Acc 68.0945,\n",
            "Epoch: 9, Training Loss: 0.0021, Acc 65.4274, Validation Loss: 0.0068, Acc 66.5445, Testing Loss: 0.0071, Acc 68.2366,\n",
            "Epoch: 10, Training Loss: 0.0021, Acc 65.7353, Validation Loss: 0.0056, Acc 68.4960, Testing Loss: 0.0071, Acc 66.5293,\n",
            "Epoch: 11, Training Loss: 0.0008, Acc 66.9103, Validation Loss: 0.0052, Acc 65.8228, Testing Loss: 0.0071, Acc 69.5681,\n",
            "Epoch: 12, Training Loss: 0.0017, Acc 67.2931, Validation Loss: 0.0083, Acc 64.8742, Testing Loss: 0.0072, Acc 69.5797,\n",
            "Epoch: 13, Training Loss: 0.0013, Acc 67.5788, Validation Loss: 0.0082, Acc 63.3388, Testing Loss: 0.0070, Acc 68.5108,\n",
            "Epoch: 14, Training Loss: 0.0018, Acc 66.6555, Validation Loss: 0.0070, Acc 65.4294, Testing Loss: 0.0071, Acc 68.5714,\n",
            "Epoch: 15, Training Loss: 0.0025, Acc 66.1835, Validation Loss: 0.0041, Acc 66.3172, Testing Loss: 0.0070, Acc 67.4312,\n",
            "Epoch: 16, Training Loss: 0.0017, Acc 66.3562, Validation Loss: 0.0041, Acc 65.5771, Testing Loss: 0.0071, Acc 67.5463,\n",
            "Epoch: 17, Training Loss: 0.0025, Acc 66.4727, Validation Loss: 0.0068, Acc 66.9610, Testing Loss: 0.0072, Acc 70.3820,\n",
            "Epoch: 18, Training Loss: 0.0021, Acc 67.9939, Validation Loss: 0.0024, Acc 66.2912, Testing Loss: 0.0072, Acc 68.0739,\n",
            "Epoch: 19, Training Loss: 0.0021, Acc 64.9197, Validation Loss: 0.0070, Acc 65.8825, Testing Loss: 0.0071, Acc 68.5470,\n",
            "Epoch: 20, Training Loss: 0.0021, Acc 67.6316, Validation Loss: 0.0070, Acc 64.8164, Testing Loss: 0.0073, Acc 69.2802,\n",
            "Epoch: 21, Training Loss: 0.0012, Acc 66.7557, Validation Loss: 0.0042, Acc 68.0257, Testing Loss: 0.0072, Acc 68.8289,\n",
            "Epoch: 22, Training Loss: 0.0016, Acc 66.5261, Validation Loss: 0.0057, Acc 66.8421, Testing Loss: 0.0070, Acc 66.8850,\n",
            "Epoch: 23, Training Loss: 0.0008, Acc 66.0825, Validation Loss: 0.0041, Acc 65.2211, Testing Loss: 0.0071, Acc 69.1935,\n",
            "Epoch: 24, Training Loss: 0.0008, Acc 65.8318, Validation Loss: 0.0057, Acc 64.9505, Testing Loss: 0.0072, Acc 69.9866,\n",
            "Epoch: 25, Training Loss: 0.0021, Acc 67.0667, Validation Loss: 0.0085, Acc 67.3322, Testing Loss: 0.0071, Acc 68.1959,\n",
            "Epoch: 26, Training Loss: 0.0016, Acc 68.9964, Validation Loss: 0.0069, Acc 67.4395, Testing Loss: 0.0071, Acc 69.1659,\n",
            "Epoch: 27, Training Loss: 0.0012, Acc 65.0507, Validation Loss: 0.0098, Acc 66.8290, Testing Loss: 0.0071, Acc 69.8618,\n",
            "Epoch: 28, Training Loss: 0.0017, Acc 67.0921, Validation Loss: 0.0112, Acc 62.9043, Testing Loss: 0.0070, Acc 68.2975,\n",
            "Epoch: 29, Training Loss: 0.0008, Acc 66.8209, Validation Loss: 0.0112, Acc 69.2267, Testing Loss: 0.0071, Acc 67.1033,\n",
            "Epoch: 30, Training Loss: 0.0008, Acc 65.8079, Validation Loss: 0.0042, Acc 67.8717, Testing Loss: 0.0072, Acc 67.1313,\n",
            "Epoch: 31, Training Loss: 0.0016, Acc 65.7050, Validation Loss: 0.0067, Acc 67.0119, Testing Loss: 0.0072, Acc 68.9327,\n",
            "Epoch: 32, Training Loss: 0.0013, Acc 68.2813, Validation Loss: 0.0041, Acc 65.7571, Testing Loss: 0.0072, Acc 68.6300,\n",
            "Epoch: 33, Training Loss: 0.0017, Acc 65.5646, Validation Loss: 0.0027, Acc 67.4795, Testing Loss: 0.0070, Acc 66.4573,\n",
            "Epoch: 34, Training Loss: 0.0012, Acc 65.3859, Validation Loss: 0.0084, Acc 64.2668, Testing Loss: 0.0072, Acc 66.9793,\n",
            "Epoch: 35, Training Loss: 0.0016, Acc 65.4720, Validation Loss: 0.0068, Acc 65.4945, Testing Loss: 0.0074, Acc 69.5865,\n",
            "Epoch: 36, Training Loss: 0.0016, Acc 67.2373, Validation Loss: 0.0084, Acc 66.1901, Testing Loss: 0.0072, Acc 68.5276,\n",
            "Epoch: 37, Training Loss: 0.0012, Acc 67.0346, Validation Loss: 0.0072, Acc 68.0266, Testing Loss: 0.0072, Acc 67.6168,\n",
            "Epoch: 38, Training Loss: 0.0025, Acc 66.8559, Validation Loss: 0.0055, Acc 66.0003, Testing Loss: 0.0073, Acc 68.1798,\n",
            "Epoch: 39, Training Loss: 0.0021, Acc 66.2639, Validation Loss: 0.0061, Acc 65.2159, Testing Loss: 0.0072, Acc 71.7776,\n",
            "Epoch: 40, Training Loss: 0.0012, Acc 69.5356, Validation Loss: 0.0028, Acc 64.0811, Testing Loss: 0.0072, Acc 69.2545,\n",
            "Epoch: 41, Training Loss: 0.0016, Acc 67.0881, Validation Loss: 0.0070, Acc 67.3000, Testing Loss: 0.0072, Acc 70.9807,\n",
            "Epoch: 42, Training Loss: 0.0013, Acc 67.5521, Validation Loss: 0.0069, Acc 68.5068, Testing Loss: 0.0071, Acc 68.8836,\n",
            "Epoch: 43, Training Loss: 0.0020, Acc 66.1633, Validation Loss: 0.0069, Acc 64.0677, Testing Loss: 0.0071, Acc 68.9775,\n",
            "Epoch: 44, Training Loss: 0.0012, Acc 68.1097, Validation Loss: 0.0069, Acc 64.9811, Testing Loss: 0.0072, Acc 68.7151,\n",
            "Epoch: 45, Training Loss: 0.0012, Acc 67.5116, Validation Loss: 0.0058, Acc 67.5598, Testing Loss: 0.0072, Acc 70.2033,\n",
            "Epoch: 46, Training Loss: 0.0008, Acc 66.4498, Validation Loss: 0.0083, Acc 67.5983, Testing Loss: 0.0073, Acc 67.3254,\n",
            "Epoch: 47, Training Loss: 0.0012, Acc 67.0837, Validation Loss: 0.0068, Acc 67.2137, Testing Loss: 0.0071, Acc 67.8587,\n",
            "Epoch: 48, Training Loss: 0.0025, Acc 66.2982, Validation Loss: 0.0083, Acc 65.3613, Testing Loss: 0.0071, Acc 68.0467,\n",
            "Epoch: 49, Training Loss: 0.0017, Acc 66.5009, Validation Loss: 0.0069, Acc 68.3138, Testing Loss: 0.0071, Acc 65.6398,\n",
            "Epoch: 50, Training Loss: 0.0013, Acc 68.4934, Validation Loss: 0.0069, Acc 68.4988, Testing Loss: 0.0071, Acc 68.8719,\n",
            "\n",
            "************* Fold : 3 **************\n",
            "Epoch: 1, Training Loss: 0.0020, Acc 67.6058, Validation Loss: 0.0025, Acc 67.4203, Testing Loss: 0.0071, Acc 66.8694,\n",
            "Epoch: 2, Training Loss: 0.0042, Acc 66.8996, Validation Loss: 0.0023, Acc 66.1309, Testing Loss: 0.0072, Acc 67.7363,\n",
            "Epoch: 3, Training Loss: 0.0042, Acc 67.8891, Validation Loss: 0.0025, Acc 68.5719, Testing Loss: 0.0071, Acc 70.1615,\n",
            "Epoch: 4, Training Loss: 0.0042, Acc 66.5801, Validation Loss: 0.0041, Acc 65.8290, Testing Loss: 0.0071, Acc 69.5604,\n",
            "Epoch: 5, Training Loss: 0.0049, Acc 66.1645, Validation Loss: 0.0024, Acc 65.5455, Testing Loss: 0.0071, Acc 69.1641,\n",
            "Epoch: 6, Training Loss: 0.0041, Acc 66.7996, Validation Loss: 0.0025, Acc 67.8778, Testing Loss: 0.0072, Acc 68.9040,\n",
            "Epoch: 7, Training Loss: 0.0027, Acc 66.6555, Validation Loss: 0.0025, Acc 68.6465, Testing Loss: 0.0071, Acc 68.7072,\n",
            "Epoch: 8, Training Loss: 0.0012, Acc 63.8750, Validation Loss: 0.0016, Acc 68.9632, Testing Loss: 0.0071, Acc 71.1906,\n",
            "Epoch: 9, Training Loss: 0.0014, Acc 67.1816, Validation Loss: 0.0041, Acc 68.4909, Testing Loss: 0.0070, Acc 68.2169,\n",
            "Epoch: 10, Training Loss: 0.0034, Acc 67.4558, Validation Loss: 0.0024, Acc 67.8955, Testing Loss: 0.0072, Acc 69.8906,\n",
            "Epoch: 11, Training Loss: 0.0028, Acc 68.4406, Validation Loss: 0.0032, Acc 66.8843, Testing Loss: 0.0071, Acc 71.1594,\n",
            "Epoch: 12, Training Loss: 0.0048, Acc 68.1228, Validation Loss: 0.0016, Acc 64.2536, Testing Loss: 0.0071, Acc 67.5995,\n",
            "Epoch: 13, Training Loss: 0.0043, Acc 66.0517, Validation Loss: 0.0033, Acc 66.7561, Testing Loss: 0.0071, Acc 68.7624,\n",
            "Epoch: 14, Training Loss: 0.0029, Acc 67.2497, Validation Loss: 0.0041, Acc 64.5344, Testing Loss: 0.0071, Acc 68.6570,\n",
            "Epoch: 15, Training Loss: 0.0027, Acc 66.5944, Validation Loss: 0.0015, Acc 64.8078, Testing Loss: 0.0070, Acc 67.8115,\n",
            "Epoch: 16, Training Loss: 0.0034, Acc 66.5449, Validation Loss: 0.0025, Acc 66.7629, Testing Loss: 0.0072, Acc 68.5771,\n",
            "Epoch: 17, Training Loss: 0.0027, Acc 67.7866, Validation Loss: 0.0025, Acc 67.5373, Testing Loss: 0.0073, Acc 69.3230,\n",
            "Epoch: 18, Training Loss: 0.0042, Acc 66.4674, Validation Loss: 0.0033, Acc 68.6102, Testing Loss: 0.0072, Acc 67.4140,\n",
            "Epoch: 19, Training Loss: 0.0035, Acc 67.8671, Validation Loss: 0.0017, Acc 66.7777, Testing Loss: 0.0071, Acc 67.5450,\n",
            "Epoch: 20, Training Loss: 0.0035, Acc 67.0817, Validation Loss: 0.0018, Acc 66.7839, Testing Loss: 0.0072, Acc 69.2103,\n",
            "Epoch: 21, Training Loss: 0.0020, Acc 68.0113, Validation Loss: 0.0025, Acc 68.5700, Testing Loss: 0.0072, Acc 70.2763,\n",
            "Epoch: 22, Training Loss: 0.0035, Acc 65.4073, Validation Loss: 0.0041, Acc 63.0911, Testing Loss: 0.0071, Acc 69.0318,\n",
            "Epoch: 23, Training Loss: 0.0039, Acc 66.2764, Validation Loss: 0.0032, Acc 65.4988, Testing Loss: 0.0071, Acc 69.0724,\n",
            "Epoch: 24, Training Loss: 0.0036, Acc 66.0163, Validation Loss: 0.0042, Acc 65.9745, Testing Loss: 0.0071, Acc 69.6381,\n",
            "Epoch: 25, Training Loss: 0.0035, Acc 67.4387, Validation Loss: 0.0042, Acc 68.0007, Testing Loss: 0.0070, Acc 69.1118,\n",
            "Epoch: 26, Training Loss: 0.0026, Acc 64.3017, Validation Loss: 0.0015, Acc 67.6336, Testing Loss: 0.0071, Acc 66.9214,\n",
            "Epoch: 27, Training Loss: 0.0048, Acc 66.3377, Validation Loss: 0.0041, Acc 66.8112, Testing Loss: 0.0071, Acc 67.1413,\n",
            "Epoch: 28, Training Loss: 0.0035, Acc 67.2095, Validation Loss: 0.0042, Acc 67.5973, Testing Loss: 0.0071, Acc 68.1788,\n",
            "Epoch: 29, Training Loss: 0.0048, Acc 66.9373, Validation Loss: 0.0050, Acc 64.4034, Testing Loss: 0.0071, Acc 68.4965,\n",
            "Epoch: 30, Training Loss: 0.0033, Acc 65.7193, Validation Loss: 0.0033, Acc 66.2511, Testing Loss: 0.0070, Acc 69.0667,\n",
            "Epoch: 31, Training Loss: 0.0014, Acc 67.7238, Validation Loss: 0.0017, Acc 66.1626, Testing Loss: 0.0071, Acc 70.2349,\n",
            "Epoch: 32, Training Loss: 0.0035, Acc 67.4774, Validation Loss: 0.0041, Acc 69.2617, Testing Loss: 0.0071, Acc 68.3888,\n",
            "Epoch: 33, Training Loss: 0.0021, Acc 65.6035, Validation Loss: 0.0043, Acc 66.1203, Testing Loss: 0.0072, Acc 67.2106,\n",
            "Epoch: 34, Training Loss: 0.0034, Acc 66.2510, Validation Loss: 0.0016, Acc 68.2604, Testing Loss: 0.0071, Acc 65.4062,\n",
            "Epoch: 35, Training Loss: 0.0042, Acc 66.2347, Validation Loss: 0.0042, Acc 66.0406, Testing Loss: 0.0071, Acc 68.9267,\n",
            "Epoch: 36, Training Loss: 0.0043, Acc 68.1726, Validation Loss: 0.0034, Acc 66.1578, Testing Loss: 0.0071, Acc 67.1099,\n",
            "Epoch: 37, Training Loss: 0.0021, Acc 67.0886, Validation Loss: 0.0017, Acc 66.1217, Testing Loss: 0.0072, Acc 71.8828,\n",
            "Epoch: 38, Training Loss: 0.0020, Acc 67.6054, Validation Loss: 0.0042, Acc 68.3364, Testing Loss: 0.0072, Acc 71.2511,\n",
            "Epoch: 39, Training Loss: 0.0044, Acc 66.7909, Validation Loss: 0.0034, Acc 68.2781, Testing Loss: 0.0071, Acc 68.6249,\n",
            "Epoch: 40, Training Loss: 0.0022, Acc 66.2426, Validation Loss: 0.0008, Acc 66.0972, Testing Loss: 0.0072, Acc 70.9144,\n",
            "Epoch: 41, Training Loss: 0.0021, Acc 67.8193, Validation Loss: 0.0025, Acc 63.9888, Testing Loss: 0.0072, Acc 69.2990,\n",
            "Epoch: 42, Training Loss: 0.0051, Acc 66.8607, Validation Loss: 0.0034, Acc 68.1795, Testing Loss: 0.0070, Acc 69.1525,\n",
            "Epoch: 43, Training Loss: 0.0035, Acc 63.8700, Validation Loss: 0.0043, Acc 71.1004, Testing Loss: 0.0069, Acc 69.0269,\n",
            "Epoch: 44, Training Loss: 0.0034, Acc 67.4819, Validation Loss: 0.0025, Acc 65.8937, Testing Loss: 0.0072, Acc 67.9158,\n",
            "Epoch: 45, Training Loss: 0.0042, Acc 64.6681, Validation Loss: 0.0050, Acc 67.1395, Testing Loss: 0.0071, Acc 67.9191,\n",
            "Epoch: 46, Training Loss: 0.0042, Acc 70.1786, Validation Loss: 0.0025, Acc 64.6025, Testing Loss: 0.0071, Acc 70.6599,\n",
            "Epoch: 47, Training Loss: 0.0036, Acc 67.8303, Validation Loss: 0.0031, Acc 67.8155, Testing Loss: 0.0071, Acc 67.3899,\n",
            "Epoch: 48, Training Loss: 0.0035, Acc 66.0208, Validation Loss: 0.0050, Acc 65.2838, Testing Loss: 0.0071, Acc 68.2756,\n",
            "Epoch: 49, Training Loss: 0.0043, Acc 64.7901, Validation Loss: 0.0033, Acc 65.5034, Testing Loss: 0.0071, Acc 66.3126,\n",
            "Epoch: 50, Training Loss: 0.0056, Acc 67.0944, Validation Loss: 0.0033, Acc 68.5976, Testing Loss: 0.0071, Acc 68.8869,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 60.0, 'y_pred')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}